{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RANKQA_NLA_PROJECT_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpfa-vjXBCTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# Index: 1 : Done\n",
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUBCA7W-BHAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Constants:\n",
        "    cuda = False\n",
        "    batch_size = 256\n",
        "    epochs = 500\n",
        "    reg = 0.00005\n",
        "    linearD = 512\n",
        "    learning_rate = 0.0005\n",
        "    MODEL_PATH = '/content/drive/My Drive/nla_models/'\n",
        "    DATA_PATH = '/content/drive/My Drive/nla_data/'\n",
        "    datasets = ['SQuAD', 'WikiMovies']\n",
        "    features = ['sum_span_score', 'sum_doc_score', 'doc_score', 'span_score', 'min_doc_score', 'max_doc_score', 'avg_doc_score',\n",
        "                'max_span_score', 'min_span_score', 'avg_span_score', 'first_occ', 'num_occ', 'context_len', 'question_len']\n",
        "\n",
        "    preprocess = np.log\n",
        "    normalization_scheme = \"normal\"\n",
        "    maximum_depth = 2\n",
        "    maximum_depth_per_question = 2\n",
        "    validation_set_split = 0.9\n",
        "    early_stopping = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXkX8R0iBMHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bootstrap():\n",
        "    try:\n",
        "        drive.mount('/content/drive', force_remount=False)\n",
        "        if not os.path.exists(Constants.DATA_PATH):\n",
        "            raise Exception\n",
        "        print(\"Data Path exists:\" + str(Constants.DATA_PATH))\n",
        "        if not os.path.exists(Constants.MODEL_PATH):\n",
        "            raise Exception\n",
        "        print(\"Model Path exists:\" + str(Constants.MODEL_PATH))\n",
        "    except:\n",
        "        print(\"FATAL: Something went terribly wrong!, Exiting...\")\n",
        "        exit(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OADSMDN0BOPO",
        "colab_type": "code",
        "outputId": "8a4fb5d8-f48d-46a6-d338-fcf39d5f9479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "bootstrap()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Data Path exists:/content/drive/My Drive/nla_data/\n",
            "Model Path exists:/content/drive/My Drive/nla_models/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMyGHqD8BQnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class DatasetHelper(object):\n",
        "    supported_datasets = [\"SQuAD\", \"WikiMovies\"]\n",
        "\n",
        "    dataset_train_format = {\"SQuAD\": \"SQuAD-v1.1-train-default-pipeline.preds-part-\",\n",
        "                            \"WikiMovies\": \"WikiMovies-train-default-pipeline.preds-part-\"}\n",
        "\n",
        "    dataset_train_count = {\"SQuAD\": 88, \"WikiMovies\": 97}\n",
        "\n",
        "    dataset_test_format = {\"SQuAD\": \"SQuAD-v1.1-dev-default-pipeline.preds-part-\",\n",
        "                           \"WikiMovies\": \"WikiMovies-test-default-pipeline.preds-part-\"}\n",
        "\n",
        "    dataset_test_count = {\"SQuAD\": 11, \"WikiMovies\": 10}\n",
        "\n",
        "    def __init__(self, datasets=[\"SQuAD\"]):\n",
        "        self.datasets = []\n",
        "        self.train_files = None\n",
        "        self.test_files = None\n",
        "        for dataset in datasets:\n",
        "            if dataset not in DatasetHelper.dataset_train_format:\n",
        "                print(\"WARNING: \" + dataset +\n",
        "                      \" is not supported, ignoring this dataset\")\n",
        "                continue\n",
        "            self.datasets.append(dataset)\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_dataset_train_file(dataset, number):\n",
        "        return Constants.DATA_PATH + DatasetHelper.dataset_train_format[dataset]+str(number)\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_dataset_test_file(dataset, number):\n",
        "        return Constants.DATA_PATH + DatasetHelper.dataset_test_format[dataset]+str(number)\n",
        "\n",
        "    def get_train_files(self):\n",
        "        if self.train_files is not None:\n",
        "            return self.train_files\n",
        "\n",
        "        self.train_files = []\n",
        "\n",
        "        for dataset in self.datasets:\n",
        "            new_train_files = []\n",
        "            for i in range(DatasetHelper.dataset_train_count[dataset]):\n",
        "                new_train_files.append(\n",
        "                    DatasetHelper._get_dataset_train_file(dataset, i))\n",
        "            self.train_files.append(new_train_files)\n",
        "\n",
        "        return self.train_files\n",
        "\n",
        "    def get_test_files(self):\n",
        "\n",
        "        if self.test_files is not None:\n",
        "            return self.test_files\n",
        "\n",
        "        self.test_files = []\n",
        "\n",
        "        for dataset in self.datasets:\n",
        "            new_test_files = []\n",
        "            for i in range(DatasetHelper.dataset_test_count[dataset]):\n",
        "                new_test_files.append(\n",
        "                    DatasetHelper._get_dataset_test_file(dataset, i))\n",
        "            self.test_files.append(new_test_files)\n",
        "\n",
        "        return self.test_files\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_pairs(data):\n",
        "        training_pairs = []\n",
        "        new_pairs = 0\n",
        "        limit = len(data) - 1 if len(data) - \\\n",
        "            1 < Constants.maximum_depth else Constants.maximum_depth\n",
        "\n",
        "        for i in range(limit):\n",
        "            if data[i]['target'] == data[i + 1]['target']:\n",
        "                continue\n",
        "            new_pairs += 1\n",
        "            x = (data[i], data[i + 1]\n",
        "                 ) if data[i]['target'] == 1 else (data[i + 1], data[i])\n",
        "            training_pairs.append(x)\n",
        "            if new_pairs >= Constants.maximum_depth_per_question:\n",
        "                break\n",
        "\n",
        "        return training_pairs\n",
        "\n",
        "    def get_train_datsets_count(self):\n",
        "        return len(self.train_files)\n",
        "    \n",
        "\n",
        "    def generate_subsample(self, feature_descriptors):\n",
        "        subsample, subsample_valid = [],  []\n",
        "        features = copy.deepcopy(feature_descriptors)\n",
        "        values = [[]] * len(features)\n",
        "        min_length = 1000000000000\n",
        "        for file_names in self.train_files:\n",
        "            new_sample, new_sample_valid = [], []\n",
        "            for file_name in file_names:\n",
        "                if not os.path.exists(file_name):\n",
        "                    print(\n",
        "                        \"WARNING: File missing, ignoring the file: {}\".format(file_name))\n",
        "                    continue\n",
        "                f = open(file_name, 'r')\n",
        "                for line in f:\n",
        "                    answers = json.loads(line)\n",
        "                    if len(answers) < 1:\n",
        "                        continue\n",
        "\n",
        "                    for answer_candiate in answers:\n",
        "                        for i, feature in enumerate(features):\n",
        "                            value = answer_candiate[feature['name']]\n",
        "                            values[i].append(value)\n",
        "\n",
        "                    subsampled = DatasetHelper.generate_pairs(answers)\n",
        "\n",
        "                    if len(subsampled) == 0:\n",
        "                        continue\n",
        "\n",
        "                    if random.random() < Constants.validation_set_split:\n",
        "                        new_sample.extend(subsampled)\n",
        "                    else:\n",
        "                        new_sample_valid.extend(subsampled)\n",
        "                f.close()\n",
        "\n",
        "            subsample.append(new_sample)\n",
        "            subsample_valid.append(new_sample_valid)\n",
        "            min_length = len(new_sample_valid) if len(\n",
        "                new_sample_valid) < min_length else min_length\n",
        "\n",
        "        train, valid = [], []\n",
        "\n",
        "        for i in range(self.get_train_datsets_count()):\n",
        "            train.extend(subsample[i])\n",
        "            train_split, valid_split = subsample[i][\n",
        "                min_length:], subsample_valid[i][0:min_length]\n",
        "            train.extend(train_split)\n",
        "            valid.extend(valid_split)\n",
        "\n",
        "        for i, feature in enumerate(features):\n",
        "            feature['mean'] = np.mean(values[i])\n",
        "            feature['max'] = np.max(values[i])\n",
        "            feature['min'] = np.min(values[i])\n",
        "            feature['std'] = np.std(values[i])\n",
        "            # FeaturesHelper.plot_features(values[i])\n",
        "\n",
        "        return train, valid, features\n",
        "\n",
        "    def generate_test_data(self, file_names):\n",
        "        self.test_data = []\n",
        "        for file_name in file_names:\n",
        "            if not os.path.exists(file_name):\n",
        "                print(\"WARNING: File missing, ignoring the file: {}\".format(file_name))\n",
        "                continue\n",
        "            f = open(file_name, 'r')\n",
        "            for line in f:\n",
        "                self.test_data.append(json.loads(line))\n",
        "\n",
        "    def build_test_dataset(self, features):\n",
        "        x, y, types, questions, answers = [], [], [], [], []\n",
        "        for data in self.test_data:\n",
        "            tx, ty, ans, i = [], [], [], 0\n",
        "            for d in data:\n",
        "                ok, qtype = FeaturesHelper.get_feature_vector(d, features,True)\n",
        "                types.append(qtype)\n",
        "                tx.append(ok)\n",
        "                ty.append(d['target'])\n",
        "                ans.append(d['context'])\n",
        "                if i == 0:\n",
        "                  questions.append(d['question'])\n",
        "                  i += 1\n",
        "            x.append(tx)\n",
        "            y.append(ty)\n",
        "            answers.append(ans)\n",
        "        return x, y, types, questions, answers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9cc11VvBuqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeaturesHelper(object):\n",
        "    NER_DICT = {'location': 0, 'person': 1, 'organization': 2, 'money': 3, 'percent': 4, 'date': 5, 'time': 6, 'o': 7,\n",
        "                'set': 8, 'duration': 9, 'number': 10, 'ordinal': 11, 'misc': 12}\n",
        "\n",
        "    POS_DICT = {'NNP': 0, 'JJ': 1, 'NN': 2, 'IN': 3, ',': 4, 'CC': 5, 'DT': 6, 'VBG': 7, 'VB': 8, 'NNS': 9, 'POS': 10,\n",
        "                'VBZ': 11, 'RB': 12, 'TO': 13, 'FW': 14, 'PRP$': 15, 'CD': 16, 'VBN': 17, 'NNPS': 18, 'JJR': 19, 'VBP': 20,\n",
        "                ':': 21, 'VBD': 22, 'PRP': 23, '#': 24, 'JJS': 25, '$': 26, 'WRB': 27, '-LRB-': 28, '-RRB-': 29, '.': 30,\n",
        "                '``': 31, \"''\": 32, 'PDT': 33, 'MD': 34, 'WP': 35, 'RP': 36, 'WDT': 37, 'EX': 38, 'UH': 39, 'SYM': 40,\n",
        "                'LS': 41, 'RBS': 42, 'RBR': 43, 'WP$': 44}\n",
        "\n",
        "    Q_TYPE = {'what was': 0, 'what is': 1, 'what': 2, 'in what': 3, 'in which': 4, 'in': 5,\n",
        "              'when': 6, 'where': 7, 'who': 8, 'why': 9, 'which': 10, 'is': 11, 'other': 12}\n",
        "\n",
        "    def __init__(self, features, preprocess, normalization_scheme):\n",
        "        self.feature_descriptors = []\n",
        "        for feature_name in features:\n",
        "            # if 'span' not in feature_name:\n",
        "            self.feature_descriptors.append(\n",
        "                 {\"name\": feature_name, \"normalization_scheme\": normalization_scheme, \"preprocess\": preprocess})\n",
        "\n",
        "    def get_features(self):\n",
        "        return self.feature_descriptors\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_jaccard_index(words_list1, words_list2):\n",
        "        a = set(words_list1)\n",
        "        b = set(words_list2)\n",
        "        c = a.intersection(b)\n",
        "        return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "    \n",
        "    @staticmethod\n",
        "    def plot_features(vals):\n",
        "        vals = (vals - np.min(vals)) / (np.max(vals) - np.min(vals))\n",
        "        vals = np.round_(vals, decimals = 5)\n",
        "        req = {}\n",
        "        for i in vals:\n",
        "          if i not in req:\n",
        "            req[i] = 0\n",
        "          req[i] += 1\n",
        "        # plt.figure(figsize=(12, 4))\n",
        "        plt.bar(req.keys(), req.values(), 1, color='g')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_ner_pos_vector(data, name):\n",
        "        provider = FeaturesHelper.NER_DICT if name == 'ner' else FeaturesHelper.POS_DICT\n",
        "        vec = np.zeros(len(provider))\n",
        "        for value in data['span_'+name]:\n",
        "            v = value.lower() if name == 'ner' else value\n",
        "            vec[provider[v]] = 1\n",
        "        return vec\n",
        "\n",
        "    @staticmethod\n",
        "    def get_qtype_vector(data):\n",
        "        vec = np.zeros(len(FeaturesHelper.Q_TYPE))\n",
        "        qwords = data['question'].lower().split(' ')\n",
        "        other = True\n",
        "        typp = \"Other\"\n",
        "        if qwords[0] in FeaturesHelper.Q_TYPE:\n",
        "            vec[FeaturesHelper.Q_TYPE[qwords[0]]] = 1\n",
        "            other = False\n",
        "            typp = qwords[0]\n",
        "        if len(qwords) > 1:\n",
        "          double_word = qwords[0] + ' ' + qwords[1]\n",
        "          if double_word in FeaturesHelper.Q_TYPE:\n",
        "              vec[FeaturesHelper.Q_TYPE[double_word]] = 1\n",
        "              other = False\n",
        "              typp += (\" , \" + double_word)\n",
        "        if other:\n",
        "            vec[FeaturesHelper.Q_TYPE['other']] = 1\n",
        "        return vec, typp\n",
        "\n",
        "    @staticmethod\n",
        "    def do_normalization(data, feature):\n",
        "        value = data[feature[\"name\"]]\n",
        "        # return value\n",
        "        if 'preprocess' in feature:\n",
        "            value = feature['preprocess'](value)\n",
        "        if 'normalization_scheme' not in feature:\n",
        "            return value\n",
        "        return value\n",
        "        if feature['normalization_scheme'] == 'normal':\n",
        "            return (value - feature['mean']) / feature['std']\n",
        "        if feature['normalization_scheme'] == 'minmax':\n",
        "            return (value - feature['min']) / (feature['max'] - feature['min'])\n",
        "\n",
        "    @staticmethod\n",
        "    def get_feature_vector(data, features, forTest=False):\n",
        "        ner = FeaturesHelper.get_ner_pos_vector(data, 'ner')\n",
        "        pos = FeaturesHelper.get_ner_pos_vector(data, 'pos')\n",
        "        qtype,typp = FeaturesHelper.get_qtype_vector(data)\n",
        "\n",
        "        normalized_features = np.zeros(len(features) + 1)\n",
        "        for i, feature in enumerate(features):\n",
        "            normalized_features[i] = FeaturesHelper.do_normalization(\n",
        "                data, feature)\n",
        "\n",
        "        para_tokens = data['context']['tokens']\n",
        "        question_tokens = data['question_tokens']\n",
        "        normalized_features[-1] = FeaturesHelper.calculate_jaccard_index(\n",
        "            para_tokens, question_tokens)\n",
        "\n",
        "        all_features = (ner, pos, qtype, normalized_features) \n",
        "        if forTest:\n",
        "          return torch.from_numpy(np.concatenate(all_features, axis=-1)).float(), typp  \n",
        "        return torch.from_numpy(np.concatenate(all_features, axis=-1)).float()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INvYKvJtByhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_helper = DatasetHelper(Constants.datasets)\n",
        "train_files = dataset_helper.get_train_files()\n",
        "test_files = dataset_helper.get_test_files()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8olqqmqQOND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_helper = FeaturesHelper(\n",
        "    Constants.features, Constants.preprocess, Constants.normalization_scheme)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M93pZsSmB01v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, valid_data, features = dataset_helper.generate_subsample(\n",
        "    features_helper.get_features())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNIs8MLICDqZ",
        "colab_type": "code",
        "outputId": "635a04fe-47d4-4375-b959-4b947b7e8ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        }
      },
      "source": [
        "print(len(train_data))\n",
        "stop, total = 0, 0\n",
        "for ques in train_data:\n",
        "  for ans in ques:\n",
        "    if ans['num_occ'] > 1:\n",
        "      stop = 1\n",
        "      for i in ans:\n",
        "        if i != 'context':\n",
        "          print(i, \":\",ans[i])\n",
        "      for i in ans['context']:\n",
        "        print(i, \":\", ans['context'][i])\n",
        "  if stop == 1:\n",
        "    break\n",
        "print(stop, total)\n",
        "print(len(valid_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178380\n",
            "qid : 6\n",
            "doc_id : Notre Dame Fighting Irish football rivalries\n",
            "span : twice\n",
            "doc_score : 348.2196698942894\n",
            "span_score : 270.06732177734375\n",
            "context_len : 235\n",
            "question_len : 10\n",
            "question : How often is Notre Dame 's the Juggler published ?\n",
            "first_occ : 3\n",
            "num_occ : 4\n",
            "sum_doc_score : 1260.2189824220168\n",
            "sum_span_score : 528.9819183349609\n",
            "avg_span_score : 132.24547958374023\n",
            "max_span_score : 270.06732177734375\n",
            "min_span_score : 16.562332153320312\n",
            "avg_doc_score : 315.0547456055042\n",
            "max_doc_score : 348.2196698942894\n",
            "min_doc_score : 295.7261535188909\n",
            "question_tokens : ['How', 'often', 'is', 'Notre', 'Dame', \"'s\", 'the', 'Juggler', 'published', '?']\n",
            "span_tokens : ['twice']\n",
            "span_ner : ['O']\n",
            "span_pos : ['RB']\n",
            "target : 1\n",
            "text : The Fighting Irish and Nebraska Cornhuskers first met in 1915 and played each other annually through 1925. During the years of Notre Dame's famed Four Horsemen backfield from 1922–24, the Fighting Irish compiled a record of 27–2–1, with their only losses coming to Nebraska in Lincoln (1922 & 1923). The Fighting Irish won in 1924 in South Bend and Nebraska won in 1925 in Lincoln, evening up the series at 5–5–1 (the 0–0 tie occurring in 1918). The Huskers were replaced on Notre Dame's schedule with USC. They met twice during the Frank Leahy era in 1947 and 1948 (with the Fighting Irish winning 31–0 and 44–13, respectively) and squared off in the 1973 Orange Bowl, a game in which the Huskers handed the Fighting Irish their worst defeat under Ara Parseghian, 40–6. More recently, there was a home-and-home series in 2000-01 (with the Huskers winning 27–24 and 27–10, respectively). The 2000 game was a memorable one, as #1 Nebraska escaped a Fighting Irish defeat in overtime on a touchdown run by Heisman winner Eric Crouch. Nebraska leads the series 8–7–1.\n",
            "start : 516\n",
            "end : 521\n",
            "tokens : ['The', 'Fighting', 'Irish', 'and', 'Nebraska', 'Cornhuskers', 'first', 'met', 'in', '1915', 'and', 'played', 'each', 'other', 'annually', 'through', '1925', '.', 'During', 'the', 'years', 'of', 'Notre', 'Dame', \"'s\", 'famed', 'Four', 'Horsemen', 'backfield', 'from', '1922', '--', '24', ',', 'the', 'Fighting', 'Irish', 'compiled', 'a', 'record', 'of', '27', '--', '2', '--', '1', ',', 'with', 'their', 'only', 'losses', 'coming', 'to', 'Nebraska', 'in', 'Lincoln', '(', '1922', '&', '1923', ')', '.', 'The', 'Fighting', 'Irish', 'won', 'in', '1924', 'in', 'South', 'Bend', 'and', 'Nebraska', 'won', 'in', '1925', 'in', 'Lincoln', ',', 'evening', 'up', 'the', 'series', 'at', '5', '--', '5', '--', '1', '(', 'the', '0', '--', '0', 'tie', 'occurring', 'in', '1918', ')', '.', 'The', 'Huskers', 'were', 'replaced', 'on', 'Notre', 'Dame', \"'s\", 'schedule', 'with', 'USC', '.', 'They', 'met', 'twice', 'during', 'the', 'Frank', 'Leahy', 'era', 'in', '1947', 'and', '1948', '(', 'with', 'the', 'Fighting', 'Irish', 'winning', '31', '--', '0', 'and', '44', '--', '13', ',', 'respectively', ')', 'and', 'squared', 'off', 'in', 'the', '1973', 'Orange', 'Bowl', ',', 'a', 'game', 'in', 'which', 'the', 'Huskers', 'handed', 'the', 'Fighting', 'Irish', 'their', 'worst', 'defeat', 'under', 'Ara', 'Parseghian', ',', '40', '--', '6', '.', 'More', 'recently', ',', 'there', 'was', 'a', 'home-and-home', 'series', 'in', '2000-01', '(', 'with', 'the', 'Huskers', 'winning', '27', '--', '24', 'and', '27', '--', '10', ',', 'respectively', ')', '.', 'The', '2000', 'game', 'was', 'a', 'memorable', 'one', ',', 'as', '#', '1', 'Nebraska', 'escaped', 'a', 'Fighting', 'Irish', 'defeat', 'in', 'overtime', 'on', 'a', 'touchdown', 'run', 'by', 'Heisman', 'winner', 'Eric', 'Crouch', '.', 'Nebraska', 'leads', 'the', 'series', '8', '--', '7', '--', '1', '.']\n",
            "1 0\n",
            "9472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Qa5Zk_DX5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Evaluator(object):\n",
        "    def __init__(self, X, y, name,types, questions, answers):\n",
        "        self.X, self.y = X, y\n",
        "        self.name = name\n",
        "        self.n = len(self.y)\n",
        "        self.base, self.curr, self.top = 0, 0, 0\n",
        "        self.types = types\n",
        "        self.total_dist, self.wrong_dist = {}, {}\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "\n",
        "    def initial_params(self):\n",
        "        X, y, questions, answers = [], [], [], []\n",
        "        with torch.no_grad():\n",
        "            for i, x in enumerate(self.X):\n",
        "                inputs = []\n",
        "                solvable = False\n",
        "                for j, candidate in enumerate(x):\n",
        "                    if self.y[i][j] == 1:\n",
        "                        solvable = True\n",
        "                self.base += int(self.y[i][0])\n",
        "                if not solvable:\n",
        "                    continue\n",
        "                X.append(x)\n",
        "                questions.append(self.questions[i])\n",
        "                answers.append(self.answers[i])\n",
        "                y.append(self.y[i])\n",
        "                self.top += 1\n",
        "                if self.types[i] not in self.total_dist:\n",
        "                  self.total_dist[self.types[i]] = 0\n",
        "                  self.wrong_dist[self.types[i]] = 0\n",
        "                self.total_dist[self.types[i]] += 1\n",
        "        self.X, self.y = X, y\n",
        "        self.questions, self.answers = questions, answers\n",
        "        self.base = self.base / self.n\n",
        "        self.top = self.top / self.n\n",
        "\n",
        "    def evaluate(self, model):\n",
        "        wrong, correct = [], []\n",
        "        self.wrong_dist.clear()\n",
        "        with torch.no_grad():\n",
        "            for i, x in enumerate(self.X):\n",
        "                inputs = []\n",
        "                for j, candidate in enumerate(x):\n",
        "                    inputs.append(candidate)\n",
        "                scores = model.predict(torch.stack(inputs))\n",
        "                j = np.argmax(scores[0:10])\n",
        "                self.curr += int(self.y[i][j])        \n",
        "                if int(self.y[i][j]) == 0:\n",
        "                    if self.types[i] not in self.wrong_dist:\n",
        "                      self.wrong_dist[self.types[i]] = 0\n",
        "                    self.wrong_dist[self.types[i]] += 1\n",
        "                    wrong.append([i, j])\n",
        "                else:\n",
        "                  correct.append([i, j])\n",
        "\n",
        "        self.curr = self.curr / self.n\n",
        "        return correct, wrong"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoUFShLBDaef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluators = []\n",
        "for i, dataset in enumerate(test_files):\n",
        "    dataset_helper.generate_test_data(dataset)\n",
        "    x, y, types, questions, answers = dataset_helper.build_test_dataset(features)\n",
        "    evaluators.append(Evaluator(x, y, i, types, questions, answers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oftLq4JiDa-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PairwiseRankingDataSet():\n",
        "\n",
        "    def __init__(self, subsampled, normalizers):\n",
        "        self.Xa, self.Xb, self.y = [], [], []\n",
        "        for xa, xb in subsampled:\n",
        "            if random.randint(1, 2) == 1:\n",
        "                self.Xa.append((FeaturesHelper.get_feature_vector(xa, normalizers)))\n",
        "                self.Xb.append((FeaturesHelper.get_feature_vector(xb, normalizers)))\n",
        "                self.y.append(torch.tensor(float(xa['target'])))\n",
        "            else:\n",
        "                self.Xa.append((FeaturesHelper.get_feature_vector(xb, normalizers)))\n",
        "                self.Xb.append((FeaturesHelper.get_feature_vector(xa, normalizers)))\n",
        "                self.y.append(torch.tensor(float(xb['target'])))\n",
        "        self.num_feat = len(self.Xa[0])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.Xa[index], self.Xb[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icrWGa15DbJ5",
        "colab_type": "code",
        "outputId": "50daf81d-2a28-4bc4-cdd9-4ca9c30c9b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Index: 14 : Done\n",
        "train_dataset = PairwiseRankingDataSet(train_data, features)\n",
        "valid_dataset = PairwiseRankingDataSet(valid_data, features)\n",
        "\n",
        "# Test: Need not run\n",
        "print(len(train_dataset), len(valid_dataset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178380 9472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylLdQT8jEDFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batchify_pair(batch):\n",
        "    xa = torch.stack([ex[0] for ex in batch])\n",
        "    xb = torch.stack([ex[1] for ex in batch])\n",
        "    y = torch.stack([ex[2] for ex in batch])\n",
        "    return xa, xb, y\n",
        "\n",
        "# Index: 16 : Done\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=Constants.batch_size,\n",
        "    sampler=torch.utils.data.sampler.RandomSampler(train_dataset),\n",
        "    pin_memory=Constants.cuda,\n",
        "    collate_fn=batchify_pair\n",
        ")\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=Constants.batch_size,\n",
        "    sampler=torch.utils.data.sampler.RandomSampler(valid_dataset),\n",
        "    pin_memory=Constants.cuda,\n",
        "    collate_fn=batchify_pair\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM18ISHMD5kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RankNetModel(nn.Module):\n",
        "\n",
        "    def __init__(self,  feat_size):\n",
        "        super(RankNetModel, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(feat_size, Constants.linearD)\n",
        "        self.activ2 = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(int(Constants.linearD), 1)\n",
        "\n",
        "        self.output_sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputl):\n",
        "        return self.output_sig(self._forward_pass(inputl))\n",
        "\n",
        "    def forward_pairwise(self, input1, input2):\n",
        "        s1 = self._forward_pass(input1)\n",
        "        s2 = self._forward_pass(input2)\n",
        "\n",
        "        out = self.output_sig(s1 - s2)\n",
        "        # out = self.output_sig(s1)\n",
        "        return out\n",
        "\n",
        "    def _forward_pass(self, input_sample):\n",
        "        out = self.linear(input_sample)\n",
        "        out = self.activ2(out)\n",
        "        out = self.linear2(out)\n",
        "        return out\n",
        "\n",
        "    def predict(self, input):\n",
        "        return self._forward_pass(input)\n",
        "\n",
        "# Index: 18 : Done\n",
        "\n",
        "\n",
        "class RankerNet(object):\n",
        "\n",
        "    def __init__(self, num_feat):\n",
        "        self.network = RankNetModel(num_feat)\n",
        "        self.optimizer = optim.Adam(self.network.parameters(), lr=Constants.learning_rate)\n",
        "        self.loss_func = nn.functional.mse_loss\n",
        "        self.loss_func_single = nn.functional.mse_loss\n",
        "\n",
        "    def predict(self, input):\n",
        "        self.network.eval()\n",
        "        input = Variable(input)\n",
        "        scores = self.network.predict(input)\n",
        "        return scores.data.cpu()\n",
        "\n",
        "    def eval_pairwise(self, input_l, input_r, targets):\n",
        "        self.network.eval()\n",
        "        with torch.no_grad():\n",
        "            targets = Variable(targets)\n",
        "            input_l = Variable(input_l)\n",
        "            input_r = Variable(input_r)\n",
        "\n",
        "            y_pred = self.network.forward_pairwise(input_l, input_r)\n",
        "\n",
        "            loss = self.loss_func_single(y_pred[:, 0], targets)\n",
        "        return loss.item()\n",
        "\n",
        "    def update_pairwise(self, input_l, input_r, targets):\n",
        "        self.network.train()\n",
        "\n",
        "        self.network.zero_grad()\n",
        "        targets = Variable(targets)\n",
        "        input_l = Variable(input_l)\n",
        "        input_r = Variable(input_r)\n",
        "\n",
        "        y_pred = self.network.forward_pairwise(input_l, input_r)\n",
        "\n",
        "        loss = self.loss_func_single(y_pred[:, 0], targets)\n",
        "        l2_reg = None\n",
        "\n",
        "        for W in self.network.parameters():\n",
        "            if l2_reg is None:\n",
        "                l2_reg = W.norm(2)\n",
        "            else:\n",
        "                l2_reg = l2_reg + W.norm(2)\n",
        "\n",
        "        loss = loss + Constants.reg * l2_reg\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.network, path)\n",
        "        pass\n",
        "\n",
        "    def load(self, path):\n",
        "        self.network = torch.load(path)\n",
        "        pass\n",
        "\n",
        "\n",
        "def calculate_loss(data_loader, model , typ):\n",
        "    loss = []\n",
        "    for data in data_loader:\n",
        "        inl, inr, target = data\n",
        "        l = model.eval_pairwise(inl, inr, target) if typ == \"val\" else model.update_pairwise(inl, inr, target)\n",
        "        loss.append(l)\n",
        "    return np.mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RtFNxs8c3mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot(total, wrong):\n",
        "  wrong_percent = {}\n",
        "  for i in wrong:\n",
        "    print(total[i], wrong[i], i)\n",
        "    wrong_percent[i] = wrong[i] / total[i]\n",
        "  plt.figure(figsize=(12, 4))\n",
        "  plt.bar(wrong_percent.keys(), wrong_percent.values(), 0.5, color='g')\n",
        "  plt.show()\n",
        "  return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-r48zIftrTj",
        "colab_type": "code",
        "outputId": "2b3b15da-bea0-4b49-885f-8d331c4493a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        }
      },
      "source": [
        "initiallywrong = []\n",
        "model = RankerNet(train_dataset.num_feat)\n",
        "\n",
        "for evaluator in evaluators:\n",
        "    evaluator.initial_params()\n",
        "\n",
        "for evaluator in evaluators:\n",
        "    _, wrongans = evaluator.evaluate(model)\n",
        "    print(evaluator.curr)\n",
        "    initiallywrong.append(wrongans)\n",
        "    plot(evaluator.total_dist, evaluator.wrong_dist)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.011921227944710623\n",
            "1103 637 which\n",
            "214 129 where\n",
            "2507 1304 what\n",
            "1116 562 what , what was\n",
            "325 138 what , what is\n",
            "2196 961 who\n",
            "2737 1128 Other\n",
            "189 118 in , in what\n",
            "976 584 when\n",
            "113 51 in\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAD4CAYAAADmbIA7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAVRUlEQVR4nO3df5Rnd13f8ecruy4VElCbkXL2Bxtx0a6KQYZFRXCVcLrRukGJmhykxiJbzukaPDSUpbVJSO2pwlGO2PVAVI4UoRtEjaNuG2zEEqCB3Zg1uJuuLAttNrWyhFillSQL7/5x75Cv09md78zc78zsfp6Pc+bs997vZ+59f+7e772vud/7I1WFJEmS1JqLVrsASZIkaTUYhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJatL61ZrxpZdeWlu3bl2t2UuSJKkR99xzz2eqamru+FULwlu3buXw4cOrNXtJkiQ1Isl/n2+8p0ZIkiSpSQZhSZIkNckgLEmSpCYZhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJapJBWJIkSU0yCEuSJKlJq/ZkOUmStLLyhqzq/OumWtX5S3N5RFiSJElNMghLkiSpSQZhSZIkNckgLEmSpCaNFYST7EpyPMmJJPvO0uaHkhxLcjTJu4ctU5IkSRrWgneNSLIO2A+8GDgFHEoyU1XHRtpsA14PPL+qHk7y1ZMqWJIkSRrCOLdP2wGcqKqTAEkOAFcBx0bavBLYX1UPA1TVp4cuVMPx9jmSJEnjBeGNwAMjw6eA581p80yAJB8C1gE3V9V/mjuhJHuAPQBbtmxZSr2SJElL4oEgzTXUxXLrgW3ATuBa4JeTfMXcRlV1a1VNV9X01NTUQLOWJEmSFm+cIPwgsHlkeFM/btQpYKaqHquqTwJ/RheMJUmSpDVpnCB8CNiW5LIkG4BrgJk5bW6nOxpMkkvpTpU4OWCdkiRJ0qAWDMJVdQbYC9wB3A+8p6qOJrklye6+2R3AQ0mOAe8HXltVD02qaEmSJGm5xrlYjqo6CBycM+7GkdcFvKb/kSRJktY8nywnSZKkJo11RPhC4+1TJEmS5BFhSZIkNckgLEmSpCYZhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJapJBWJIkSU0yCEuSJKlJBmFJkiQ1ySAsSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmrV/tAqSVljdkVedfN9Wqzl+SJHU8IixJkqQmGYQlSZLUJIOwJEmSmjRWEE6yK8nxJCeS7Jvn/euSnE5ypP/58eFLlSRJkoaz4MVySdYB+4EXA6eAQ0lmqurYnKa3VdXeCdQoSZIkDW6cu0bsAE5U1UmAJAeAq4C5QVjSecC7ZkiS1Bnn1IiNwAMjw6f6cXO9NMl9Sd6bZPN8E0qyJ8nhJIdPnz69hHIlSZKkYQx1sdzvAlur6lnAHwDvmK9RVd1aVdNVNT01NTXQrCVJkqTFGycIPwiMHuHd1I/7kqp6qKoe6Qd/BXjOMOVJkiRJkzFOED4EbEtyWZINwDXAzGiDJE8bGdwN3D9ciZIkSdLwFrxYrqrOJNkL3AGsA95eVUeT3AIcrqoZ4Poku4EzwGeB6yZYsyRJkrRs49w1gqo6CBycM+7GkdevB14/bGmSJEnS5PhkOUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNckgLEmSpCaN9YhlSZIknd/yhqzq/OumWtX5z8cjwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNcmL5SSpIV4sI0mP84iwJEmSmmQQliRJUpMMwpIkSWqS5whLaornyEqSZnlEWJIkSU0yCEuSJKlJBmFJkiQ1yXOEJUnN8BxxSaPGOiKcZFeS40lOJNl3jnYvTVJJpocrUZIkSRregkE4yTpgP3AlsB24Nsn2edpdArwa+MjQRUqSJElDG+eI8A7gRFWdrKpHgQPAVfO0+9fAzwKfH7A+SZIkaSLGCcIbgQdGhk/1474kybcAm6vq9881oSR7khxOcvj06dOLLlaSJEkayrLvGpHkIuDngX+2UNuqurWqpqtqempqarmzliRJkpZsnCD8ILB5ZHhTP27WJcA3An+U5FPAtwIzXjAnSZKktWycIHwI2JbksiQbgGuAmdk3q+p/V9WlVbW1qrYCdwO7q+rwRCqWJEmSBrBgEK6qM8Be4A7gfuA9VXU0yS1Jdk+6QEmSJGkSxnqgRlUdBA7OGXfjWdruXH5ZkiRJ0mT5iGVJkiQ1ySAsSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNckgLEmSpCYZhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJapJBWJIkSU0yCEuSJKlJYwXhJLuSHE9yIsm+ed5/VZKPJTmS5INJtg9fqiRJkjScBYNwknXAfuBKYDtw7TxB991V9U1VdTnwRuDnB69UkiRJGtA4R4R3ACeq6mRVPQocAK4abVBVfzUy+CSghitRkiRJGt76MdpsBB4YGT4FPG9uoyT/FHgNsAH47vkmlGQPsAdgy5Yti61VkiRJGsxgF8tV1f6qegbwOuCnztLm1qqarqrpqampoWYtSZIkLdo4QfhBYPPI8KZ+3NkcAF6ynKIkSZKkSRsnCB8CtiW5LMkG4BpgZrRBkm0jg98LfHy4EiVJkqThLXiOcFWdSbIXuANYB7y9qo4muQU4XFUzwN4kVwCPAQ8DPzrJoiVJkqTlGudiOarqIHBwzrgbR16/euC6JEmSpInyyXKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNckgLEmSpCYZhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJapJBWJIkSU0yCEuSJKlJBmFJkiQ1ySAsSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKTxgrCSXYlOZ7kRJJ987z/miTHktyX5M4kTx++VEmSJGk4CwbhJOuA/cCVwHbg2iTb5zS7F5iuqmcB7wXeOHShkiRJ0pDGOSK8AzhRVSer6lHgAHDVaIOqen9V/d9+8G5g07BlSpIkScMaJwhvBB4YGT7VjzubVwD/cb43kuxJcjjJ4dOnT49fpSRJkjSwQS+WS/IjwDTwpvner6pbq2q6qqanpqaGnLUkSZK0KOvHaPMgsHlkeFM/7m9JcgXwL4HvrKpHhilPkiRJmoxxjggfArYluSzJBuAaYGa0QZJnA28DdlfVp4cvU5IkSRrWgkG4qs4Ae4E7gPuB91TV0SS3JNndN3sTcDHwG0mOJJk5y+QkSZKkNWGcUyOoqoPAwTnjbhx5fcXAdUmSJEkT5ZPlJEmS1CSDsCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNckgLEmSpCYZhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJapJBWJIkSU0yCEuSJKlJBmFJkiQ1ySAsSZKkJo0VhJPsSnI8yYkk++Z5/4VJ/jjJmSRXD1+mJEmSNKwFg3CSdcB+4EpgO3Btku1zmv0P4Drg3UMXKEmSJE3C+jHa7ABOVNVJgCQHgKuAY7MNqupT/XtfnECNkiRJ0uDGOTViI/DAyPCpfpwkSZJ03lrRi+WS7ElyOMnh06dPr+SsJUmSpL9lnCD8ILB5ZHhTP27RqurWqpququmpqamlTEKSJEkaxDhB+BCwLcllSTYA1wAzky1LkiRJmqwFg3BVnQH2AncA9wPvqaqjSW5JshsgyXOTnAJ+EHhbkqOTLFqSJElarnHuGkFVHQQOzhl348jrQ3SnTEiSJEnnBZ8sJ0mSpCYZhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJapJBWJIkSU0yCEuSJKlJBmFJkiQ1ySAsSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNckgLEmSpCaNFYST7EpyPMmJJPvmef8JSW7r3/9Ikq1DFypJkiQNacEgnGQdsB+4EtgOXJtk+5xmrwAerqqvBd4M/OzQhUqSJElDGueI8A7gRFWdrKpHgQPAVXPaXAW8o3/9XuBFSTJcmZIkSdKwUlXnbpBcDeyqqh/vh18OPK+q9o60+dO+zal++BN9m8/MmdYeYE8/+HXA8aE6ssIuBT6zYKsLl/23//a/Xfbf/tv/dp3P/X96VU3NHbl+JSuoqluBW1dynpOQ5HBVTa92HavF/tt/+2//V7uO1WL/7b/9v7D6P86pEQ8Cm0eGN/Xj5m2TZD3wFOChIQqUJEmSJmGcIHwI2JbksiQbgGuAmTltZoAf7V9fDfxhLXTOhSRJkrSKFjw1oqrOJNkL3AGsA95eVUeT3AIcrqoZ4FeBdyY5AXyWLixfyM770zuWyf63zf63zf63zf637YLr/4IXy0mSJEkXIp8sJ0mSpCYZhCVJktQkg/BZJPncWca/Ksk/Osfv7Uzye5OrbGWcrf8tWuyy6NeBb7+Q60mytb9/+GJ+5yXzPJVyyJouuOWy0PZmJV2I24Qkm5L8TpKPJ/lEkl9IsiHJ5Um+Z6TdzUluWM1azyXJhweazu4k+4aY1sg0V/1zuVQX4jq/FEOtX2uVQXiRquqtVfXvV7uOtay/hV7LdgJrYkPe28naqOcldI9pXyt2ssaXi9ubyemffvpbwO1VtQ14JnAx8G+Ay4HvOcevL3Ze64aa1nyqapD1uKpmqupnhpjWMuxkbXwu1Rtq/VqzqqrJH+C1wPX96zfT3fIN4LuBdwGfo9sg/glwN/DU/v2bgRv6118L/Oe+zR8Dz6D7EP8R3aOm/1s/rax2fwfs/xTwm3S31TsEPH9kubwT+BDwH87Wbi3+LGNZfB/wEeDefj14KrAV+F9099Y+ArxgyFr61xOvB9gP7O5f/zbd3WIA/nE/763A/cAvA0eB9wFf3rd5Zf9//if9OvBEuh3bZ4FP9nU8Y2Re6/rxAb4C+ALwwv69DwDbgLf0be4F/idwd//+j9E95ehI/3u/dKEsl5HP1ez25nrgGHAfcGANfQ62An/Y13UnsGW1P9Nj9vdFwAfmjHsy8DDwaeB0/3/yw/3/w9vptu0nZ5dT/zs/Any0b/s2YN3I5/Tn+uX1HRPuy+f6f3eyjP0PcB3w7/rXv0b3uftw3+erF7vOjCyHFdl+ruA6f6794Lzryfn8M9T6tVZ/Wj4ifBfwgv71NHBxki/rx30AeBLdzvab++FXzjONdwH7+zbfDvx5P/7ZwE/SHeX5GuD5k+rEMiy1/78AvLmqngu8FPiVkWluB66oqmsXaLfWLHVZfBD41qp6NnAA+OdV9SngrXR9v7yq7hq4FlaontE6NvL4EcvROrbRrf/fAPwl3f8zwG9V1XP7+u4HXlFVH6a73/hr+zo+MTujqvoC3ePWtwPfQfdH5QuSPAHYXFUfB24H7un79hDwzH65vAr4naq6nO4brjsvlOUyj33As6vqWX2/h7bUz8EvAu/o63oXXXg6H3wDcM/oiKr6K+BTwE8Dt/X/J7f1b3898A+AHcBNSb4syd+nC8rP79fBLwAv69s/CfhIVX1zVX1w4r153JD7n6fRfSb/ITDfkeK1sr1aqknsB/+/9WTCfVhp50O+WZSWv8K+B3hOkicDj9DtfKfpPgDXA48CvzfS9sWjv5zkEmBjVf02QFV9vh8P8NGqOtUPH6H7K3clN4TjWGr/rwC29/0EeHKSi/vXM1X1N+dqV1Vr8ZyrpS6LTcBtSZ4GbKA7qjfpWliheu4CfrI/d/UY8JX9dL+tr+PvAp+sqiMjdWztX39jkp+mO7p7Md09yMeZ3wuBy4B/S7fD+S90R1vo+3JlkmPAFrplME13VPU7k7wOeIzuq+7Zei6E5TLqPuBdSW6n+8NgaEv9HHwb8AP963cCb5xAbWvB71fVI8AjST5NdwTzRcBzgEP9tu7L6Y4mQxeKf3MV6hxy/3N7VX0ROJbkqfO8v1a2V0s1if3gfOvJqUl3ZAWdD/lmUZo9IlxVj9F98K6j++rnLuC76E53uB94rPrvAug2aIv5o+GRkdeL/d0VsYz+X0T3V/zl/c/GkXD7f0Zmca52a8oylsUv0n2N+E3APwH+zgrUwkrUU1UP0gW2XXRHQu4CfojuK7K/7pudbT3/NWBvX8cbxqzjA3Q7nx3AwX7eO/v5AtxEtzN5K90DfM7QLZdL6I6+/E0//++ap57zebmM+l66UzO+hS54DbpdmfA2cS06Rhdiv6QPRFvo1q+55vt/Dd3R8Nnt3NdV1c19m8/333astCH3P6PTytw318r2aqkmtB9c8/v/Zbrg+tdsEO7dBdzA4zu0VwH3jqz4Z9Xv9E4leQlAkickeeIki52ApfT/fcBPzA4kuXyZ7daKpSyLp9CdywaPP2Ic4K/pAtpK1rKkepLsSHK2i7HupvsKbLaOG3g8mJ7LJcCf918Jvmxk/LmWy0fpTi/6Yv/tyhG6nePs16tP6cfdAHwl8Hm65XIcOFlVb6ELL8+aZ9rn83KZreciutNE3g+8jq5PF5/rd5ZoKeveh3n8aaIvY7xlsRbcCTxx9q4c/QVtP0f3B8tfMN5n+E7g6iRf3U/jq5I8fTLlDifJ3v6JsUNYse3VhExyP6jzgEG4Owfqv1bVX9DtXBezEX85cH2S++h2Bn9v+BInain9vx6YTnJf/zX12c5VHLfdWrGUZXEz8BtJ7qG7YGvW7wLfn+RIkhfM+5vD17LUerbQHU09Wx3rq+oE3VeGXzVmHf+K7iKYD9FdUDHrAPDaJPcmecboL/RfJT5AFzJn530J8LF++I10QXkz3bn4X6RbLo8Bf9p/RXcRMF94vZnzdLmMWAf8epKP0V1c9Jaq+ssx5rlYS1n3fgL4sX47+HLg1ROoa3B90Pl+4AeTfBz4M7r+/gvg/XRffR9J8sPnmMYx4KeA9/X9/wO65bfWfT3dufZDWMnt1SRMcj+o84CPWJYaluRNwDur6r7VrmUtcbnoQpbuXvc/UFWPrnYt0mozCEuSJKlJrZ8aIUmSpEYZhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJapJBWJIkSU36f+DQXY3SoWN5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.027735017149843364\n",
            "11942 5736 what\n",
            "992 455 Other\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0zlJ0z1ELrk",
        "colab_type": "code",
        "outputId": "93423998-242a-4e15-bddb-9a3186b8731d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(train_dataset.num_feat)\n",
        "# Index: 20 : Done\n",
        "model_save_path = Constants.MODEL_PATH + 'dry_run' + '.out'\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "best_val_iteration = 0\n",
        "\n",
        "for i in range(Constants.epochs):\n",
        "    print('EPOCH '+str(i))\n",
        "    train_loss = calculate_loss(train_loader, model,'train')\n",
        "    val_loss = calculate_loss(valid_loader, model,'val')\n",
        "\n",
        "    print('Train loss '+ str(train_loss))\n",
        "    print('Validation loss '+str(val_loss))\n",
        "\n",
        "    if best_val_loss > val_loss:\n",
        "        print('Got a new best model, SAVING!!')\n",
        "        model.save(model_save_path)\n",
        "        best_val_loss = val_loss\n",
        "        best_val_iteration = 0\n",
        "\n",
        "    best_val_iteration += 1\n",
        "\n",
        "    if best_val_iteration > Constants.early_stopping:\n",
        "        print(\"doing early stopping\")\n",
        "        break\n",
        "\n",
        "model.load(model_save_path)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86\n",
            "EPOCH 0\n",
            "Train loss 0.12059119218690495\n",
            "Validation loss 0.11416456667152611\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.10988466444838167\n",
            "Validation loss 0.11042052889997894\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 2\n",
            "Train loss 0.10657993173881446\n",
            "Validation loss 0.10734419544806352\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 3\n",
            "Train loss 0.10495830233204827\n",
            "Validation loss 0.10701194204188683\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 4\n",
            "Train loss 0.10394803474161513\n",
            "Validation loss 0.10508979071636458\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 5\n",
            "Train loss 0.10279137143060843\n",
            "Validation loss 0.10391966092425424\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 6\n",
            "Train loss 0.10179323180334127\n",
            "Validation loss 0.10359527231068225\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 7\n",
            "Train loss 0.10101254368828906\n",
            "Validation loss 0.10294074927632874\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 8\n",
            "Train loss 0.10016469714075456\n",
            "Validation loss 0.1022721440405459\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 9\n",
            "Train loss 0.09937672729642695\n",
            "Validation loss 0.10210169972600164\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 10\n",
            "Train loss 0.09879554035289044\n",
            "Validation loss 0.10178312820357245\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 11\n",
            "Train loss 0.0981487256382596\n",
            "Validation loss 0.10056043174621221\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 12\n",
            "Train loss 0.09760610499503451\n",
            "Validation loss 0.10038954825014682\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 13\n",
            "Train loss 0.097167688214796\n",
            "Validation loss 0.10033825643964715\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 14\n",
            "Train loss 0.09650234969992891\n",
            "Validation loss 0.10017193672624794\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 15\n",
            "Train loss 0.09630021205976327\n",
            "Validation loss 0.0992788118687836\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 16\n",
            "Train loss 0.09588671634387935\n",
            "Validation loss 0.09994399547576904\n",
            "EPOCH 17\n",
            "Train loss 0.09562084617005018\n",
            "Validation loss 0.09887777631347244\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 18\n",
            "Train loss 0.09523773182669876\n",
            "Validation loss 0.0987223972742622\n",
            "Got a new best model, SAVING!!\n",
            "EPOCH 19\n",
            "Train loss 0.09488706159241059\n",
            "Validation loss 0.09919558747394665\n",
            "EPOCH 20\n",
            "Train loss 0.0947352409619341\n",
            "Validation loss 0.09873558218414719\n",
            "EPOCH 21\n",
            "Train loss 0.09458674894514864\n",
            "Validation loss 0.09904474744925627\n",
            "EPOCH 22\n",
            "Train loss 0.0941708023410018\n",
            "Validation loss 0.09925964454541335\n",
            "EPOCH 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKA2PYBetuGf",
        "colab_type": "code",
        "outputId": "d780d972-8163-4bb6-fc12-1e06531f3307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "curr_wrong, curr_correct= [], []\n",
        "for i, evaluator_ in enumerate(evaluators):\n",
        "    correct, wrong = evaluator_.evaluate(model)\n",
        "    curr_wrong.append(wrong)\n",
        "    curr_correct.append(correct)\n",
        "    print(evaluator_.curr)\n",
        "    plot(evaluator_.total_dist, evaluator_.wrong_dist)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3459173032536774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.43091146449977097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgc1OP6mpVsy",
        "colab_type": "code",
        "outputId": "049c79bc-122f-462d-bef5-861101c37fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i, wrong_set in enumerate(curr_correct):\n",
        "  curr = 0\n",
        "  for wrong in wrong_set:\n",
        "    print(evaluators[i].questions[wrong[0]])\n",
        "    x = evaluators[i].answers[wrong[0]][wrong[1]]\n",
        "    if x['start'] < len(x['tokens']):\n",
        "      for k in range(x['start'], min(x['end'], len(x['tokens']))):\n",
        "        print(x['tokens'][k], end=\" \")\n",
        "    else:\n",
        "      print(\"No answer\", end = \" \")\n",
        "    print()\n",
        "    if curr > 20: \n",
        "      break\n",
        "    curr += 1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Which NFL team represented the AFC at Super Bowl 50 ?\n",
            "No answer \n",
            "Which NFL team won Super Bowl 50 ?\n",
            "No answer \n",
            "What is the AFC short for ?\n",
            "No answer \n",
            "If Roman numerals were used , what would Super Bowl 50 have been called ?\n",
            "No answer \n",
            "What year was Super Bowl 50 ?\n",
            "No answer \n",
            "Which team won Super Bowl 50 .\n",
            "No answer \n",
            "Where was Super Bowl 50 held ?\n",
            "No answer \n",
            "The name of the NFL championship game is ?\n",
            "No answer \n",
            "Which Carolina Panthers player was named Most Valuable Player ?\n",
            "Game . They joined the Patriots , Dallas Cowboys , \n",
            "How many appearances have the Denver Broncos made in the Super Bowl ?\n",
            "No answer \n",
            "What year was the Carolina Panthers franchise founded ?\n",
            "No answer \n",
            "How many teams have been in the Super Bowl eight times ?\n",
            "No answer \n",
            "Who did Denver beat in the AFC championship ?\n",
            "No answer \n",
            "What year did the Carolina Panthers form ?\n",
            "No answer \n",
            "Which Denver linebacker was named Super Bowl MVP ?\n",
            "No answer \n",
            "How many solo tackles did Von Miller make at Super Bowl 50 ?\n",
            "No answer \n",
            "How many turnovers did Cam Newton have ?\n",
            "to the Saints with a \n",
            "What position does Von Miller play for the Denver Broncos ?\n",
            "Gostkowski 's 46-yard field goal . The next time New \n",
            "What was the number of solo tackles that Von Miller had in Super Bowl 50 ?\n",
            "No answer \n",
            "How many forced fumbles did Von Miller have during the Super Bowl 50 game ?\n",
            "No answer \n",
            "How many times did the Denver defense force Newton into turnovers ?\n",
            "win since the 2005 season \n",
            "Which network broadcasted Super Bowl 50 in the U.S. ?\n",
            "booth by color \n",
            "what does Grégoire Colin appear in ?\n",
            "Before the Rain ( , `` Pred doždot '' ) is a 1994 Macedonian film \n",
            "what films did Shahid Kapoor act in ?\n",
            "Jab We Met '' remains one of the most popular \n",
            "what films does Brigitte Nielsen appear in ?\n",
            "Red Sonja is a 1985 Dutch-American sword and sorcery \n",
            "Mona McKinnon appears in which movies ?\n",
            "No answer \n",
            "what films did Christina Ricci act in ?\n",
            "The Opposite of Sex is a 1998 American romantic comedy film written and directed by Don Roos and stars \n",
            "what films does Claude Akins appear in ?\n",
            "Battle for the Planet of the Apes \n",
            "what films did Arjun Rampal act in ?\n",
            "No answer \n",
            "what films did Melvin Van Peebles star in ?\n",
            "French . To express the ghetto 's turmoil and pathos , Van Peebles used sprechgesang as a form he could tell stories in ; he recorded three albums using this style , `` \n",
            "what films did Phil Silvers act in ?\n",
            "play the lead , and this time Silvers agreed . The revival was a hit and Silvers became the first leading actor ever to win a Tony Award in a revival of a musical . \n",
            "what films did Piolo Pascual star in ?\n",
            "No answer \n",
            "what movies was Eiji Funakoshi an actor in ?\n",
            "No answer \n",
            "what films does Richard Roundtree appear in ?\n",
            "portrayed the young Korean lover \n",
            "what movies did Darren McGavin star in ?\n",
            "No answer \n",
            "what films did Stéphane Demers act in ?\n",
            "No answer \n",
            "what films does Celia Montalván appear in ?\n",
            "Toni is a 1935 \n",
            "Judi Dench appears in which movies ?\n",
            "No answer \n",
            "what does Marlee Matlin appear in ?\n",
            "Pickering , is credited with the creation of the Harvard Classification Scheme , which was the first serious attempt to organize and classify stars \n",
            "what films did Fabiola Quiroz act in ?\n",
            "Who the Hell Is Juliette ? \n",
            "what movies did Nicole Grimaudo act in ?\n",
            "Loose Cannons ( 2010 film ) \n",
            "what movies did Max Elliott Slade act in ?\n",
            "Apollo 13 '' , young Mark Goddard in \n",
            "what films did Tamara Toumanova star in ?\n",
            "No answer \n",
            "what does Marguerite Churchill appear in ?\n",
            "Dracula 's Daughter \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6wjP1Rhf1Dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, wrong_set in enumerate(curr_wrong):\n",
        "  curr = 0\n",
        "  for wrong in wrong_set:\n",
        "    print(evaluators[i].questions[wrong[0]])\n",
        "    x = evaluators[i].answers[wrong[0]][wrong[1]]\n",
        "    if x['start'] < len(x['tokens']):\n",
        "      for k in range(x['start'], min(x['end'], len(x['tokens']))):\n",
        "        print(x['tokens'][k], end=\" \")\n",
        "    else:\n",
        "      print(\"No answer\", end = \" \")\n",
        "    print()\n",
        "    if curr > 20: \n",
        "      break\n",
        "    curr += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDfJ9BrXzwwp",
        "colab_type": "text"
      },
      "source": [
        "Where did Super Bowl 50 take place ?\n",
        "the Astrodome several years prior to Super Bowl VIII . The Orange Bowl was the only AFL stadium to host a Super Bowl and the only stadium to host consecutive Super Bowls , hosting Super Bowls II and III . \n",
        "Which NFL team won Super Bowl 50 ?\n",
        ". The Colts scored 3 TDs in 2:10 . \n",
        "What color was used to emphasize the 50th anniversary of the Super Bowl ?\n",
        "\n",
        "Who won Super Bowl 50 ?\n",
        "\n",
        "Super Bowl 50 decided the NFL champion for what season ?\n",
        "\n",
        "What year did the Denver Broncos secure a Super Bowl title for the third time ?\n",
        "\n",
        "What month , day and year did Super Bowl 50 take place ?\n",
        "have a Super Bowl \n",
        "What team was the AFC champion ?\n",
        "\n",
        "Who won Super Bowl 50 ?\n",
        "\n",
        "Super Bowl 50 determined the NFL champion for what season ?\n",
        "season record . \n",
        "What 2015 NFL team one the AFC playoff ?\n",
        "\n",
        "What team did the Panthers defeat ?\n",
        "\n",
        "Who did the Panthers beat in the NFC Championship Game ?\n",
        "\n",
        "Who lost to the Broncos in the AFC Championship ?\n",
        "\n",
        "Who were the defending Super Bowl champions ?\n",
        "\n",
        "How many teams have been in the Super Bowl eight times ?\n",
        "\n",
        "Who was this season 's NFL MVP ?\n",
        "\n",
        "What was the win/loss ratio in 2015 for the Carolina Panthers during their regular season ?\n",
        "an offensive touchdown \n",
        "How many teams have played in the Super Bowl eight times ?\n",
        "\n",
        "Which team did not get a chance to defend their Super Bowl XLIX win in Super Bowl 50 ?\n",
        "\n",
        "Who is the quarterback for the Panthers ?\n",
        "\n",
        "Who did Denver beat in the 2015 AFC Championship game ?\n",
        "\n",
        "what films did Michelle Trachtenberg star in ?\n",
        "Book Union collected a \n",
        "Brendan Gleeson appears in which movies ?\n",
        "\n",
        "what films does Brigitte Nielsen appear in ?\n",
        "\n",
        "what films does William Atherton appear in ?\n",
        "\n",
        "Ruggero Raimondi appears in which movies ?\n",
        "Angela Gheorghiu \n",
        "what films did Robert Strauss act in ?\n",
        "\n",
        "what films did Aleksandr Gordon act in ?\n",
        "\n",
        "what movies was Chris O'Donnell an actor in ?\n",
        "\n",
        "what films did Melvin Van Peebles star in ?\n",
        "\n",
        "what does Tannishtha Chatterjee appear in ?\n",
        "performance of the year . \n",
        "what movies was Michael Tully an actor in ?\n",
        "\n",
        "what movies was Dan Petronijevic an actor in ?\n",
        "\n",
        "what films did Piolo Pascual star in ?\n",
        "as Patricia Montecillo , an \n",
        "what does Nell Cattrysse star in ?\n",
        "\n",
        "what does Sharon Gans act in ?\n",
        "benefits for Lesh 's \n",
        "what does Beatrice Lillie act in ?\n",
        "\n",
        "what movies did Nicole Grimaudo act in ?\n",
        "\n",
        "what films did Agnes Ayres act in ?\n",
        "Shelbyville , Illinois . He , \n",
        "what films did Audra Lindley act in ?\n",
        "\n",
        "what films did Tamara Toumanova star in ?\n",
        "\n",
        "what films does Ralf Harolde appear in ?\n",
        "\n",
        "what movies did Sophie Rois star in ?\n",
        "who stumbled upon the bean was called `` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s8eXIX9RXCb",
        "colab_type": "text"
      },
      "source": [
        "**WITH ALL FEATURES**\n",
        "86\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.29820245979186377\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.3840434083601286\n",
        "EPOCH 0\n",
        "Train loss 0.23822287296362019\n",
        "Validation loss 0.37109774351119995\n",
        "Got a new best model, SAVING!!\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "EPOCH 1\n",
        "Train loss 0.6151828748814879\n",
        "Validation loss 0.3840262434772543\n",
        "EPOCH 2\n",
        "Train loss 0.25392582552115806\n",
        "Validation loss 0.21616457483252963\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 3\n",
        "Train loss 0.20924984502775304\n",
        "Validation loss 0.2164179582048107\n",
        "EPOCH 4\n",
        "Train loss 0.20859487007274818\n",
        "Validation loss 0.2183562541330183\n",
        "EPOCH 5\n",
        "Train loss 0.20809646052053898\n",
        "Validation loss 0.2162805433208878\n",
        "EPOCH 6\n",
        "Train loss 0.20799602941211542\n",
        "Validation loss 0.21351534208735903\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 7\n",
        "Train loss 0.20671448021999245\n",
        "Validation loss 0.21003613983457153\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 8\n",
        "Train loss 0.2508569326097191\n",
        "Validation loss 0.37065121048205607\n",
        "EPOCH 9\n",
        "Train loss 0.2019098688114184\n",
        "Validation loss 0.2032722313259099\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 10\n",
        "Train loss 0.2017279878280023\n",
        "Validation loss 0.20859725612240868\n",
        "EPOCH 11\n",
        "Train loss 0.20107396443684897\n",
        "Validation loss 0.20573178960664854\n",
        "EPOCH 12\n",
        "Train loss 0.1999712948059831\n",
        "Validation loss 0.20577842923435005\n",
        "EPOCH 13\n",
        "Train loss 0.19771120666349054\n",
        "Validation loss 0.2065236177798864\n",
        "EPOCH 14\n",
        "Train loss 0.19552490391231572\n",
        "Validation loss 0.20906037253302498\n",
        "EPOCH 15\n",
        "Train loss 0.20531005557301388\n",
        "Validation loss 0.21352773300699285\n",
        "EPOCH 16\n",
        "Train loss 0.2073136563379536\n",
        "Validation loss 0.21288699113033913\n",
        "EPOCH 17\n",
        "Train loss 0.20249303354640547\n",
        "Validation loss 0.20820266894392064\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.3039735099337748\n",
        "fraction still correct = 0.9808449938867002\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.3954983922829582\n",
        "fraction still correct = 0.9764315352697095"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCTuzYb5fyFi",
        "colab_type": "text"
      },
      "source": [
        "***WITHOUT sum features ***\n",
        "84\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.2998107852412488\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.3853496784565916\n",
        "EPOCH 0\n",
        "Train loss 0.23775713302023793\n",
        "Validation loss 0.20308961405565865\n",
        "Got a new best model, SAVING!!\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "EPOCH 1\n",
        "Train loss 0.23107947957241673\n",
        "Validation loss 0.3918383897919404\n",
        "EPOCH 2\n",
        "Train loss 0.2673755784294215\n",
        "Validation loss 0.202741534694245\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 3\n",
        "Train loss 0.21194925108903098\n",
        "Validation loss 0.21268430430638163\n",
        "EPOCH 4\n",
        "Train loss 0.21457604001993422\n",
        "Validation loss 0.21528208451835731\n",
        "EPOCH 5\n",
        "Train loss 0.3315274129439702\n",
        "Validation loss 0.37361971563414526\n",
        "EPOCH 6\n",
        "Train loss 0.32095772106114817\n",
        "Validation loss 0.20005381342611814\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 7\n",
        "Train loss 0.33187506596247357\n",
        "Validation loss 0.39384917209022924\n",
        "EPOCH 8\n",
        "Train loss 0.38340928482598274\n",
        "Validation loss 0.37920785499246495\n",
        "EPOCH 9\n",
        "Train loss 0.3807869867860586\n",
        "Validation loss 0.38309293436376674\n",
        "EPOCH 10\n",
        "Train loss 0.35556077661699265\n",
        "Validation loss 0.2130378857254982\n",
        "EPOCH 11\n",
        "Train loss 0.20053864762872115\n",
        "Validation loss 0.19908501443110013\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 12\n",
        "Train loss 0.202927158727985\n",
        "Validation loss 0.20560270469439657\n",
        "EPOCH 13\n",
        "Train loss 0.2054754189247715\n",
        "Validation loss 0.20454096519633344\n",
        "EPOCH 14\n",
        "Train loss 0.20513274978803492\n",
        "Validation loss 0.2067141097627188\n",
        "EPOCH 15\n",
        "Train loss 0.20487714361870427\n",
        "Validation loss 0.20399681910088188\n",
        "EPOCH 16\n",
        "Train loss 0.20502729801696606\n",
        "Validation loss 0.20045368530248342\n",
        "EPOCH 17\n",
        "Train loss 0.20795371308494573\n",
        "Validation loss 0.2116632041962523\n",
        "EPOCH 18\n",
        "Train loss 0.20648560625897056\n",
        "Validation loss 0.216105643855898\n",
        "EPOCH 19\n",
        "Train loss 0.21348697729622837\n",
        "Validation loss 0.21034296994146548\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.30274361400189215\n",
        "fraction still correct = 0.9940338983050847\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.39439308681672025\n",
        "fraction still correct = 0.988422097254383"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb1rWdiZliEc",
        "colab_type": "text"
      },
      "source": [
        "**WIHTOUT 'min' features**\n",
        "\n",
        "84\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.040018921475875116\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.10540594855305466\n",
        "EPOCH 0\n",
        "Train loss 0.22070005709571497\n",
        "Validation loss 0.2030413577685485\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 1\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "Train loss 0.19960331857204439\n",
        "Validation loss 0.2028731260750745\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 2\n",
        "Train loss 0.20037322318979672\n",
        "Validation loss 0.20083977966695218\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 3\n",
        "Train loss 0.2016673558311803\n",
        "Validation loss 0.19276030683839643\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 4\n",
        "Train loss 0.22282130603279388\n",
        "Validation loss 0.20602257267848864\n",
        "EPOCH 5\n",
        "Train loss 0.19778986166630472\n",
        "Validation loss 0.20298635959625244\n",
        "EPOCH 6\n",
        "Train loss 0.19987941895212447\n",
        "Validation loss 0.1988240850938333\n",
        "EPOCH 7\n",
        "Train loss 0.20090709655412606\n",
        "Validation loss 0.20213932805770152\n",
        "EPOCH 8\n",
        "Train loss 0.2036150158622435\n",
        "Validation loss 0.20175692076618607\n",
        "EPOCH 9\n",
        "Train loss 0.20020452012973172\n",
        "Validation loss 0.20190237583340825\n",
        "EPOCH 10\n",
        "Train loss 0.19962286416973388\n",
        "Validation loss 0.202161137316678\n",
        "EPOCH 11\n",
        "Train loss 0.20094354097332273\n",
        "Validation loss 0.20239267035110578\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.30558183538315986\n",
        "fraction still correct = 0.9817538126361656\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.39509646302250806\n",
        "fraction still correct = 0.9627606752730884"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeuZdAQeo68Q",
        "colab_type": "text"
      },
      "source": [
        "**WITHOUT 'max' features**\n",
        "\n",
        "84\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.30056764427625354\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.38444533762057875\n",
        "EPOCH 0\n",
        "Train loss 0.20069134602574018\n",
        "Validation loss 0.20619386072094376\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 1\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "Train loss 0.3091058416617634\n",
        "Validation loss 0.20153262043321454\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 2\n",
        "Train loss 0.29161193123604984\n",
        "Validation loss 0.20063699218066963\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 3\n",
        "Train loss 0.26131419253596944\n",
        "Validation loss 0.37075504660606384\n",
        "EPOCH 4\n",
        "Train loss 0.3779742037156933\n",
        "Validation loss 0.37116027119997386\n",
        "EPOCH 5\n",
        "Train loss 0.311137635527675\n",
        "Validation loss 0.21032937475152919\n",
        "EPOCH 6\n",
        "Train loss 0.20186208239769868\n",
        "Validation loss 0.20154883088292302\n",
        "EPOCH 7\n",
        "Train loss 0.19944580838639278\n",
        "Validation loss 0.20468653496858236\n",
        "EPOCH 8\n",
        "Train loss 0.19974709925559325\n",
        "Validation loss 0.20249560153162158\n",
        "EPOCH 9\n",
        "Train loss 0.19888881944055886\n",
        "Validation loss 0.20076756743160454\n",
        "EPOCH 10\n",
        "Train loss 0.20337621225070818\n",
        "Validation loss 0.21063997737459234\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.30454115421002836\n",
        "fraction still correct = 0.9883040935672515\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.3933882636655949\n",
        "fraction still correct = 0.9847984137475215"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14EUKtjHsUAK",
        "colab_type": "text"
      },
      "source": [
        "**WITHOUT 'avg' features**\n",
        "\n",
        "84\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.01021759697256386\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.04551848874598071\n",
        "EPOCH 0\n",
        "Train loss 0.2592987297262464\n",
        "Validation loss 0.2236709776851866\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 1\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "Train loss 0.2052530804702214\n",
        "Validation loss 0.20704853990011746\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 2\n",
        "Train loss 0.2404541619547776\n",
        "Validation loss 0.20200427662995127\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 3\n",
        "Train loss 0.32455499131764687\n",
        "Validation loss 0.36875537037849426\n",
        "EPOCH 4\n",
        "Train loss 0.3247411749618394\n",
        "Validation loss 0.36785782873630524\n",
        "EPOCH 5\n",
        "Train loss 0.4089677958403315\n",
        "Validation loss 0.3672294177942806\n",
        "EPOCH 6\n",
        "Train loss 0.3604841136506626\n",
        "Validation loss 0.3659812692138884\n",
        "EPOCH 7\n",
        "Train loss 0.30743498338120323\n",
        "Validation loss 0.20130400442414814\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 8\n",
        "Train loss 0.19661333190543312\n",
        "Validation loss 0.20415200789769491\n",
        "EPOCH 9\n",
        "Train loss 0.1990791424896036\n",
        "Validation loss 0.2037591685851415\n",
        "EPOCH 10\n",
        "Train loss 0.19889025295419352\n",
        "Validation loss 0.20312409020132488\n",
        "EPOCH 11\n",
        "Train loss 0.1975596172256129\n",
        "Validation loss 0.19923283201124933\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 12\n",
        "Train loss 0.2602915121827807\n",
        "Validation loss 0.3773460164666176\n",
        "EPOCH 13\n",
        "Train loss 0.36550438250814166\n",
        "Validation loss 0.3622078870733579\n",
        "EPOCH 14\n",
        "Train loss 0.35093347709093775\n",
        "Validation loss 0.36315470354424584\n",
        "EPOCH 15\n",
        "Train loss 0.2016026651327099\n",
        "Validation loss 0.1967666633427143\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 16\n",
        "Train loss 0.5148252396924156\n",
        "Validation loss 0.6791479802793927\n",
        "EPOCH 17\n",
        "Train loss 0.3967067581840924\n",
        "Validation loss 0.36344895015160245\n",
        "EPOCH 18\n",
        "Train loss 0.2968316437729767\n",
        "Validation loss 0.3637753129005432\n",
        "EPOCH 19\n",
        "Train loss 0.359785858137267\n",
        "Validation loss 0.363873696161641\n",
        "EPOCH 20\n",
        "Train loss 0.21297230264970235\n",
        "Validation loss 0.20493321700228584\n",
        "EPOCH 21\n",
        "Train loss 0.19966008334287574\n",
        "Validation loss 0.2042895013259517\n",
        "EPOCH 22\n",
        "Train loss 0.19989689569388117\n",
        "Validation loss 0.2044825628399849\n",
        "EPOCH 23\n",
        "Train loss 0.19948676510580948\n",
        "Validation loss 0.2055405726035436\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.30454115421002836\n",
        "fraction still correct = 0.9915715062533986\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.39610128617363344\n",
        "fraction still correct = 0.9717795484727756"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A0DcW1Cwtf-",
        "colab_type": "text"
      },
      "source": [
        "*** WITHOUT 'occ' features ***\n",
        "\n",
        "\n",
        "84\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.043519394512771994\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.08370176848874598\n",
        "EPOCH 0\n",
        "Train loss 0.27548800151262964\n",
        "Validation loss 0.1948752072122362\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 1\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "Train loss 0.228198600177254\n",
        "Validation loss 0.1923170429137018\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 2\n",
        "Train loss 0.2038878770172596\n",
        "Validation loss 0.20842190790507528\n",
        "EPOCH 3\n",
        "Train loss 0.2092313546368054\n",
        "Validation loss 0.2106097982161575\n",
        "EPOCH 4\n",
        "Train loss 0.20457437801573958\n",
        "Validation loss 0.19562134850356314\n",
        "EPOCH 5\n",
        "Train loss 0.20355552613735198\n",
        "Validation loss 0.2028735631869899\n",
        "EPOCH 6\n",
        "Train loss 0.20503105529717036\n",
        "Validation loss 0.19969296703735986\n",
        "EPOCH 7\n",
        "Train loss 0.2003940864226648\n",
        "Validation loss 0.19208349370294148\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 8\n",
        "Train loss 0.33337657028010914\n",
        "Validation loss 0.1922115476595031\n",
        "EPOCH 9\n",
        "Train loss 0.19832567905741078\n",
        "Validation loss 0.19925477521287072\n",
        "EPOCH 10\n",
        "Train loss 0.2019097578738417\n",
        "Validation loss 0.19836689655979475\n",
        "EPOCH 11\n",
        "Train loss 0.20299029188496726\n",
        "Validation loss 0.19923353319366774\n",
        "EPOCH 12\n",
        "Train loss 0.1980618104338646\n",
        "Validation loss 0.19108992401096556\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 13\n",
        "Train loss 0.2017818536928722\n",
        "Validation loss 0.1979205645620823\n",
        "EPOCH 14\n",
        "Train loss 0.20213461354374884\n",
        "Validation loss 0.19884959753188822\n",
        "EPOCH 15\n",
        "Train loss 0.202528851883752\n",
        "Validation loss 0.1987631788684262\n",
        "EPOCH 16\n",
        "Train loss 0.20287507125309537\n",
        "Validation loss 0.1986046421031157\n",
        "EPOCH 17\n",
        "Train loss 0.20000022536941936\n",
        "Validation loss 0.1989570479426119\n",
        "EPOCH 18\n",
        "Train loss 0.19751116931438445\n",
        "Validation loss 0.19221256714728144\n",
        "EPOCH 19\n",
        "Train loss 0.26590056898338454\n",
        "Validation loss 0.19749325844976637\n",
        "EPOCH 20\n",
        "Train loss 0.20165423218693052\n",
        "Validation loss 0.1988619892961449\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.3054872280037843\n",
        "fraction still correct = 0.9896598639455783\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.3960008038585209\n",
        "fraction still correct = 0.9688535453943009"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjKX7RLmzypR",
        "colab_type": "text"
      },
      "source": [
        "**  WITHOUT len features **\n",
        "\n",
        "\n",
        "84\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.3040681173131504\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.38886655948553056\n",
        "EPOCH 0\n",
        "Train loss 0.2202879874370037\n",
        "Validation loss 0.2093620900478628\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 1\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "Train loss 0.20367645877718585\n",
        "Validation loss 0.19792720385723644\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 2\n",
        "Train loss 0.36041113577167533\n",
        "Validation loss 0.37490902344385785\n",
        "EPOCH 3\n",
        "Train loss 0.36536136609197\n",
        "Validation loss 0.37671052085028756\n",
        "EPOCH 4\n",
        "Train loss 0.3046740777684413\n",
        "Validation loss 0.20339881545967525\n",
        "EPOCH 5\n",
        "Train loss 0.20193830711974037\n",
        "Validation loss 0.20097468917568526\n",
        "EPOCH 6\n",
        "Train loss 0.19906272777380088\n",
        "Validation loss 0.20226103564103445\n",
        "EPOCH 7\n",
        "Train loss 0.2012091189240798\n",
        "Validation loss 0.20145934323469797\n",
        "EPOCH 8\n",
        "Train loss 0.22088275832837803\n",
        "Validation loss 0.3739732164475653\n",
        "EPOCH 9\n",
        "Train loss 0.3626386712589155\n",
        "Validation loss 0.3706184923648834\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.30387890255439926\n",
        "fraction still correct = 0.9886008956439137\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.3903737942122186\n",
        "fraction still correct = 0.9818181818181818"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl7TOgUSQyqR",
        "colab_type": "text"
      },
      "source": [
        "**WITHOUT 'span' features**\n",
        "\n",
        "81\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.14172185430463577\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.27562299035369775\n",
        "EPOCH 0\n",
        "Train loss 0.1851319356026056\n",
        "Validation loss 0.18041472942442507\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 1\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "Train loss 0.15407885888189035\n",
        "Validation loss 0.1951460258380787\n",
        "EPOCH 2\n",
        "Train loss 0.15468871573223406\n",
        "Validation loss 0.142458886713595\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 3\n",
        "Train loss 0.15183763674997294\n",
        "Validation loss 0.13908357696758733\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 4\n",
        "Train loss 0.14857070933553113\n",
        "Validation loss 0.14727056690969983\n",
        "EPOCH 5\n",
        "Train loss 0.14645955626331855\n",
        "Validation loss 0.14032197945021294\n",
        "EPOCH 6\n",
        "Train loss 0.1462483279439001\n",
        "Validation loss 0.15584401786327362\n",
        "EPOCH 7\n",
        "Train loss 0.14310511416930155\n",
        "Validation loss 0.17239188060567184\n",
        "EPOCH 8\n",
        "Train loss 0.1447586672798929\n",
        "Validation loss 0.13869005018794858\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 9\n",
        "Train loss 0.14094103882369055\n",
        "Validation loss 0.1319737243088516\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 10\n",
        "Train loss 0.1405554941624872\n",
        "Validation loss 0.13504640576807228\n",
        "EPOCH 11\n",
        "Train loss 0.13679340995517753\n",
        "Validation loss 0.13356010152681455\n",
        "EPOCH 12\n",
        "Train loss 0.1398883292049127\n",
        "Validation loss 0.14034031613453016\n",
        "EPOCH 13\n",
        "Train loss 0.1348125678786904\n",
        "Validation loss 0.12327412556152086\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 14\n",
        "Train loss 0.13574302509874744\n",
        "Validation loss 0.12621727404562202\n",
        "EPOCH 15\n",
        "Train loss 0.1323139518073018\n",
        "Validation loss 0.14372958343576742\n",
        "EPOCH 16\n",
        "Train loss 0.1328504866625959\n",
        "Validation loss 0.1332883130054216\n",
        "EPOCH 17\n",
        "Train loss 0.13370136683207212\n",
        "Validation loss 0.12382029017081132\n",
        "EPOCH 18\n",
        "Train loss 0.13248261430957628\n",
        "Validation loss 0.12156157598302171\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 19\n",
        "Train loss 0.13189394834940354\n",
        "Validation loss 0.14835512839459084\n",
        "EPOCH 20\n",
        "Train loss 0.13062408867056277\n",
        "Validation loss 0.12006982879058735\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 21\n",
        "Train loss 0.13153172826903403\n",
        "Validation loss 0.1197196770761464\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 22\n",
        "Train loss 0.12999046674912237\n",
        "Validation loss 0.12045510294469627\n",
        "EPOCH 23\n",
        "Train loss 0.1278129509504943\n",
        "Validation loss 0.12193056739665367\n",
        "EPOCH 24\n",
        "Train loss 0.12986763791635483\n",
        "Validation loss 0.13233189123707848\n",
        "EPOCH 25\n",
        "Train loss 0.12927070659757173\n",
        "Validation loss 0.11904674728174468\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 26\n",
        "Train loss 0.12850445782890987\n",
        "Validation loss 0.12286791406773231\n",
        "EPOCH 27\n",
        "Train loss 0.12815939349912436\n",
        "Validation loss 0.11979020548027915\n",
        "EPOCH 28\n",
        "Train loss 0.12648940156713576\n",
        "Validation loss 0.12033374889476879\n",
        "EPOCH 29\n",
        "Train loss 0.12608089379017615\n",
        "Validation loss 0.11560434203695606\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 30\n",
        "Train loss 0.12581059882398668\n",
        "Validation loss 0.11743607774779603\n",
        "EPOCH 31\n",
        "Train loss 0.12608820446187335\n",
        "Validation loss 0.12171348224620561\n",
        "EPOCH 32\n",
        "Train loss 0.12633653932673394\n",
        "Validation loss 0.11853958334068994\n",
        "EPOCH 33\n",
        "Train loss 0.12461688565636568\n",
        "Validation loss 0.12094629213616655\n",
        "EPOCH 34\n",
        "Train loss 0.1247872328745449\n",
        "Validation loss 0.1255290832471203\n",
        "EPOCH 35\n",
        "Train loss 0.12350476545965211\n",
        "Validation loss 0.11496568249689566\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 36\n",
        "Train loss 0.12259156267573053\n",
        "Validation loss 0.11728384647820447\n",
        "EPOCH 37\n",
        "Train loss 0.12541351981130622\n",
        "Validation loss 0.12071036265508549\n",
        "EPOCH 38\n",
        "Train loss 0.12403233744768967\n",
        "Validation loss 0.11596045864594949\n",
        "EPOCH 39\n",
        "Train loss 0.12144541829952354\n",
        "Validation loss 0.1206524521112442\n",
        "EPOCH 40\n",
        "Train loss 0.12301972596899463\n",
        "Validation loss 0.11871953066941854\n",
        "EPOCH 41\n",
        "Train loss 0.12229369010493821\n",
        "Validation loss 0.1121226406177959\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 42\n",
        "Train loss 0.12232732653447316\n",
        "Validation loss 0.11658941269726367\n",
        "EPOCH 43\n",
        "Train loss 0.12143917493682051\n",
        "Validation loss 0.11412593098105611\n",
        "EPOCH 44\n",
        "Train loss 0.12190559000117926\n",
        "Validation loss 0.11915610609827815\n",
        "EPOCH 45\n",
        "Train loss 0.12127029782797986\n",
        "Validation loss 0.11397620250244399\n",
        "EPOCH 46\n",
        "Train loss 0.12165379968707654\n",
        "Validation loss 0.11477779999778077\n",
        "EPOCH 47\n",
        "Train loss 0.1207593682945542\n",
        "Validation loss 0.11916583393876617\n",
        "EPOCH 48\n",
        "Train loss 0.1209162250907295\n",
        "Validation loss 0.11363932812536084\n",
        "EPOCH 49\n",
        "Train loss 0.11974413202641178\n",
        "Validation loss 0.1168834164335921\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.32109744560075687\n",
        "fraction still correct = 0.9621026894865525\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.41057073954983925\n",
        "fraction still correct = 0.9146173820070261"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wyCEMnnWw4s",
        "colab_type": "text"
      },
      "source": [
        "** WITHOUT NER AND span faetures **\n",
        "\n",
        "68\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.011352885525070956\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.044614147909967844\n",
        "EPOCH 0\n",
        "Train loss 0.20121757068987056\n",
        "Validation loss 0.17561045490406654\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 1\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "Train loss 0.16019211775584624\n",
        "Validation loss 0.1851569055705457\n",
        "EPOCH 2\n",
        "Train loss 0.1572077778062766\n",
        "Validation loss 0.17837837721044952\n",
        "EPOCH 3\n",
        "Train loss 0.15567944934311853\n",
        "Validation loss 0.14812254865427274\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 4\n",
        "Train loss 0.1511367586613213\n",
        "Validation loss 0.16157461118859215\n",
        "EPOCH 5\n",
        "Train loss 0.14871842520729836\n",
        "Validation loss 0.16667066313124992\n",
        "EPOCH 6\n",
        "Train loss 0.14567111930323604\n",
        "Validation loss 0.13463185163768562\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 7\n",
        "Train loss 0.14494090189408507\n",
        "Validation loss 0.13938764825060562\n",
        "EPOCH 8\n",
        "Train loss 0.14534287092852832\n",
        "Validation loss 0.13381172213199977\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 9\n",
        "Train loss 0.1440620916617104\n",
        "Validation loss 0.14718900359160192\n",
        "EPOCH 10\n",
        "Train loss 0.1391907333794752\n",
        "Validation loss 0.14123308356549288\n",
        "EPOCH 11\n",
        "Train loss 0.13892491233237994\n",
        "Validation loss 0.14827673016367732\n",
        "EPOCH 12\n",
        "Train loss 0.1394428207148639\n",
        "Validation loss 0.1325113576006245\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 13\n",
        "Train loss 0.14003102970609338\n",
        "Validation loss 0.1347576506637238\n",
        "EPOCH 14\n",
        "Train loss 0.13696433103860534\n",
        "Validation loss 0.1345241363789584\n",
        "EPOCH 15\n",
        "Train loss 0.13515580362388505\n",
        "Validation loss 0.12987996214950406\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 16\n",
        "Train loss 0.13553901647719874\n",
        "Validation loss 0.16104631085653562\n",
        "EPOCH 17\n",
        "Train loss 0.13641778367953922\n",
        "Validation loss 0.1322222776912354\n",
        "EPOCH 18\n",
        "Train loss 0.13838214052038983\n",
        "Validation loss 0.12956004952256744\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 19\n",
        "Train loss 0.13390513279279415\n",
        "Validation loss 0.1492555997258908\n",
        "EPOCH 20\n",
        "Train loss 0.1346311682091762\n",
        "Validation loss 0.13220362425655932\n",
        "EPOCH 21\n",
        "Train loss 0.13265763334023936\n",
        "Validation loss 0.12465175100274987\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 22\n",
        "Train loss 0.13215979918816229\n",
        "Validation loss 0.14137292935236082\n",
        "EPOCH 23\n",
        "Train loss 0.1321573739122594\n",
        "Validation loss 0.139904134780974\n",
        "EPOCH 24\n",
        "Train loss 0.13218527755171103\n",
        "Validation loss 0.12599050958414335\n",
        "EPOCH 25\n",
        "Train loss 0.13222463025001327\n",
        "Validation loss 0.12297921929810499\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 26\n",
        "Train loss 0.12948462663375598\n",
        "Validation loss 0.12097395292005024\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 27\n",
        "Train loss 0.12966664626832\n",
        "Validation loss 0.15329082894164162\n",
        "EPOCH 28\n",
        "Train loss 0.12859286966924163\n",
        "Validation loss 0.1263483217036402\n",
        "EPOCH 29\n",
        "Train loss 0.12819099349525354\n",
        "Validation loss 0.13394118764915983\n",
        "EPOCH 30\n",
        "Train loss 0.1280469914341348\n",
        "Validation loss 0.1459359725987589\n",
        "EPOCH 31\n",
        "Train loss 0.12708619047217445\n",
        "Validation loss 0.12416792117260597\n",
        "EPOCH 32\n",
        "Train loss 0.12710556505149356\n",
        "Validation loss 0.11822806902833886\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 33\n",
        "Train loss 0.12695821593162498\n",
        "Validation loss 0.131493007814562\n",
        "EPOCH 34\n",
        "Train loss 0.12552341933925776\n",
        "Validation loss 0.12810736894607544\n",
        "EPOCH 35\n",
        "Train loss 0.12576996433803111\n",
        "Validation loss 0.1304940496747558\n",
        "EPOCH 36\n",
        "Train loss 0.12479378649690462\n",
        "Validation loss 0.12400471298275767\n",
        "EPOCH 37\n",
        "Train loss 0.12442869000211465\n",
        "Validation loss 0.12349907892781335\n",
        "EPOCH 38\n",
        "Train loss 0.1239909816623928\n",
        "Validation loss 0.12037173114918373\n",
        "EPOCH 39\n",
        "Train loss 0.12347591807999155\n",
        "Validation loss 0.11727368368490322\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 40\n",
        "Train loss 0.12450488577883302\n",
        "Validation loss 0.14571082008046074\n",
        "EPOCH 41\n",
        "Train loss 0.12399831783021127\n",
        "Validation loss 0.11969046818243491\n",
        "EPOCH 42\n",
        "Train loss 0.12383111083456375\n",
        "Validation loss 0.12171046395559569\n",
        "EPOCH 43\n",
        "Train loss 0.12339278793386124\n",
        "Validation loss 0.11638562703454816\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 44\n",
        "Train loss 0.12551369314456362\n",
        "Validation loss 0.12475931322252429\n",
        "EPOCH 45\n",
        "Train loss 0.1229385542809878\n",
        "Validation loss 0.11716479566451665\n",
        "EPOCH 46\n",
        "Train loss 0.12251500138354744\n",
        "Validation loss 0.12305491699560268\n",
        "EPOCH 47\n",
        "Train loss 0.12235578393646235\n",
        "Validation loss 0.11939980029254346\n",
        "EPOCH 48\n",
        "Train loss 0.12170523194028585\n",
        "Validation loss 0.11826486442540143\n",
        "EPOCH 49\n",
        "Train loss 0.12131841024530463\n",
        "Validation loss 0.1283892805914621\n",
        "EPOCH 50\n",
        "Train loss 0.12171129517800819\n",
        "Validation loss 0.11837269124147054\n",
        "EPOCH 51\n",
        "Train loss 0.12079442212510007\n",
        "Validation loss 0.11851447981757086\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.3205298013245033\n",
        "fraction still correct = 0.9969554386936064\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.41227893890675243\n",
        "fraction still correct = 0.9817973105936373"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld4ikzK0aVig",
        "colab_type": "text"
      },
      "source": [
        "**WITHOUT ner features**\n",
        "\n",
        "73\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.20860927152317882\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.16760450160771703\n",
        "EPOCH 0\n",
        "Train loss 0.2107037728529605\n",
        "Validation loss 0.20943449800078934\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 1\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "Train loss 0.214626075096834\n",
        "Validation loss 0.2250718103872763\n",
        "EPOCH 2\n",
        "Train loss 0.21396697167424555\n",
        "Validation loss 0.21082526485662204\n",
        "EPOCH 3\n",
        "Train loss 0.20619975902503063\n",
        "Validation loss 0.20466267740404284\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 4\n",
        "Train loss 0.2035903100105787\n",
        "Validation loss 0.2091001308447606\n",
        "EPOCH 5\n",
        "Train loss 0.20444731649150139\n",
        "Validation loss 0.20448258277532216\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 6\n",
        "Train loss 0.20233162277962555\n",
        "Validation loss 0.20855437460783366\n",
        "EPOCH 7\n",
        "Train loss 0.20187135188063782\n",
        "Validation loss 0.2024099798621358\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 8\n",
        "Train loss 0.19821662632988654\n",
        "Validation loss 0.2020584183770257\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 9\n",
        "Train loss 0.1991427785004449\n",
        "Validation loss 0.2004467836908392\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 10\n",
        "Train loss 0.28991951734724225\n",
        "Validation loss 0.3657226047000369\n",
        "EPOCH 11\n",
        "Train loss 0.33590813324837426\n",
        "Validation loss 0.1955529427206194\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 12\n",
        "Train loss 0.2285350468810274\n",
        "Validation loss 0.19822510714466507\n",
        "EPOCH 13\n",
        "Train loss 0.19464417661201305\n",
        "Validation loss 0.1966600869152997\n",
        "EPOCH 14\n",
        "Train loss 0.1938923206233705\n",
        "Validation loss 0.19722923837803505\n",
        "EPOCH 15\n",
        "Train loss 0.19744112914732329\n",
        "Validation loss 0.20147061509055061\n",
        "EPOCH 16\n",
        "Train loss 0.19751809079488233\n",
        "Validation loss 0.1990318084890778\n",
        "EPOCH 17\n",
        "Train loss 0.20197257254390116\n",
        "Validation loss 0.20584070521432\n",
        "EPOCH 18\n",
        "Train loss 0.2040342507099354\n",
        "Validation loss 0.20600841818629084\n",
        "EPOCH 19\n",
        "Train loss 0.2041345865046739\n",
        "Validation loss 0.20623162952629295\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.30482497634815514\n",
        "fraction still correct = 0.9635423751870493\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.397508038585209\n",
        "fraction still correct = 0.946746546846397"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK5vID_CdkhU",
        "colab_type": "text"
      },
      "source": [
        "**WITHOUT POS features**\n",
        "\n",
        "\n",
        "\n",
        "41\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.08438978240302744\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.23743971061093247\n",
        "EPOCH 0\n",
        "Train loss 0.2201383334500595\n",
        "Validation loss 0.36648921547709284\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 1\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "Train loss 0.22776496332559804\n",
        "Validation loss 0.21093029267079122\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 2\n",
        "Train loss 0.2080065832927674\n",
        "Validation loss 0.21051048749202006\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 3\n",
        "Train loss 0.2039117683178195\n",
        "Validation loss 0.20217901951557882\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 4\n",
        "Train loss 0.2012521559119395\n",
        "Validation loss 0.20315205446771673\n",
        "EPOCH 5\n",
        "Train loss 0.21624042202474733\n",
        "Validation loss 0.3622051179409027\n",
        "EPOCH 6\n",
        "Train loss 0.2047327035273264\n",
        "Validation loss 0.201414928645701\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 7\n",
        "Train loss 0.20075846387763563\n",
        "Validation loss 0.20235950278269277\n",
        "EPOCH 8\n",
        "Train loss 0.20219237418133815\n",
        "Validation loss 0.2074332104341404\n",
        "EPOCH 9\n",
        "Train loss 0.20423599516970234\n",
        "Validation loss 0.21398937702178955\n",
        "EPOCH 10\n",
        "Train loss 0.20837300165272576\n",
        "Validation loss 0.21323761706416672\n",
        "EPOCH 11\n",
        "Train loss 0.21048759337573264\n",
        "Validation loss 0.21808255322881648\n",
        "EPOCH 12\n",
        "Train loss 0.2122584448778237\n",
        "Validation loss 0.21552352325336352\n",
        "EPOCH 13\n",
        "Train loss 0.21068669132920295\n",
        "Validation loss 0.2169585477661442\n",
        "EPOCH 14\n",
        "Train loss 0.21098564825259225\n",
        "Validation loss 0.21077885539145083\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.30482497634815514\n",
        "fraction still correct = 0.9766018228812406\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.3939911575562701\n",
        "fraction still correct = 0.957327158451869"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74OY9bWTpUMB",
        "colab_type": "text"
      },
      "source": [
        "**WITHOUT Q_TYPE Features**\n",
        "\n",
        "73\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.007663197729422895\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.03667604501607717\n",
        "EPOCH 0\n",
        "Train loss 0.32317270667300185\n",
        "Validation loss 0.3733899536970499\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 1\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "Train loss 0.6920120535487774\n",
        "Validation loss 0.3921388814578185\n",
        "EPOCH 2\n",
        "Train loss 0.3760757548761231\n",
        "Validation loss 0.38117259177001744\n",
        "EPOCH 3\n",
        "Train loss 0.23040055093971912\n",
        "Validation loss 0.20702569388054512\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 4\n",
        "Train loss 0.2001509299464417\n",
        "Validation loss 0.21055376932427688\n",
        "EPOCH 5\n",
        "Train loss 0.20219494238026162\n",
        "Validation loss 0.20667220571556608\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 6\n",
        "Train loss 0.20021218190604773\n",
        "Validation loss 0.20838379900197726\n",
        "EPOCH 7\n",
        "Train loss 0.2012233270551038\n",
        "Validation loss 0.20774095646432927\n",
        "EPOCH 8\n",
        "Train loss 0.2132522203134944\n",
        "Validation loss 0.3760358578449971\n",
        "EPOCH 9\n",
        "Train loss 0.2913614668827344\n",
        "Validation loss 0.21548433843496684\n",
        "EPOCH 10\n",
        "Train loss 0.20833574483080375\n",
        "Validation loss 0.21472330028946335\n",
        "EPOCH 11\n",
        "Train loss 0.20696341207939437\n",
        "Validation loss 0.2132975072474093\n",
        "EPOCH 12\n",
        "Train loss 0.20526638787165072\n",
        "Validation loss 0.21150458181226575\n",
        "EPOCH 13\n",
        "Train loss 0.20924840800272018\n",
        "Validation loss 0.21753796049066493\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.3040681173131504\n",
        "fraction still correct = 0.9951093601412851\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.39308681672025725\n",
        "fraction still correct = 0.9717495456798282"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhSoHY1dsvbJ",
        "colab_type": "text"
      },
      "source": [
        "**WITHOUT any ner,pos,qtype features**\n",
        "\n",
        "15\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.007757805108798486\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.032455787781350484\n",
        "EPOCH 0\n",
        "Train loss 0.7188474560706185\n",
        "Validation loss 0.7076014828037571\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 1\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "Train loss 0.4969172808194912\n",
        "Validation loss 0.41830497819024165\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 2\n",
        "Train loss 0.21096091525346297\n",
        "Validation loss 0.20776297595049883\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 3\n",
        "Train loss 0.20193459321998253\n",
        "Validation loss 0.20472321196182355\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 4\n",
        "Train loss 0.19741856720949655\n",
        "Validation loss 0.19943621875466527\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 5\n",
        "Train loss 0.19630003977769767\n",
        "Validation loss 0.20186100376618876\n",
        "EPOCH 6\n",
        "Train loss 0.20055364388278699\n",
        "Validation loss 0.21329007881718712\n",
        "EPOCH 7\n",
        "Train loss 0.20702101066068113\n",
        "Validation loss 0.21410875626512477\n",
        "EPOCH 8\n",
        "Train loss 0.20445304331943434\n",
        "Validation loss 0.2066161241885778\n",
        "EPOCH 9\n",
        "Train loss 0.19968411055284108\n",
        "Validation loss 0.20304546042068586\n",
        "EPOCH 10\n",
        "Train loss 0.19614047393800535\n",
        "Validation loss 0.20160122256021243\n",
        "EPOCH 11\n",
        "Train loss 0.19920593854520247\n",
        "Validation loss 0.20812647205752297\n",
        "EPOCH 12\n",
        "Train loss 0.19892918745477425\n",
        "Validation loss 0.2072470433808662\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.3047303689687796\n",
        "fraction still correct = 0.9957840337277302\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.3945940514469453\n",
        "fraction still correct = 0.9822759648832201"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0ku_xGJYajR",
        "colab_type": "text"
      },
      "source": [
        "** WITH ONLY ner,pos,qtype features**\n",
        "\n",
        "71\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.09905392620624409\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.24517684887459806\n",
        "EPOCH 0\n",
        "Train loss 0.24755981500568308\n",
        "Validation loss 0.2469941123917296\n",
        "Got a new best model, SAVING!!\n",
        "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RankNetModel. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "EPOCH 1\n",
        "Train loss 0.2460022056435311\n",
        "Validation loss 0.24662149113577767\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 2\n",
        "Train loss 0.24503167967001596\n",
        "Validation loss 0.24640890512917493\n",
        "Got a new best model, SAVING!!\n",
        "EPOCH 3\n",
        "Train loss 0.2440873408138496\n",
        "Validation loss 0.24665716934848475\n",
        "EPOCH 4\n",
        "Train loss 0.24321458899070947\n",
        "Validation loss 0.24657460161157557\n",
        "EPOCH 5\n",
        "Train loss 0.24264481591223305\n",
        "Validation loss 0.246723281773361\n",
        "EPOCH 6\n",
        "Train loss 0.24200895548037363\n",
        "Validation loss 0.24711863897942207\n",
        "EPOCH 7\n",
        "Train loss 0.24139541018759572\n",
        "Validation loss 0.2471506462709324\n",
        "EPOCH 8\n",
        "Train loss 0.24085942102604158\n",
        "Validation loss 0.24774809705244527\n",
        "EPOCH 9\n",
        "Train loss 0.24028234173129387\n",
        "Validation loss 0.24753140114449165\n",
        "EPOCH 10\n",
        "Train loss 0.23989227181766848\n",
        "Validation loss 0.24838028807897825\n",
        "doing early stopping\n",
        "0 evaluation results w/o re-ranking: 0.30018921475875116 / upper bound: 0.5428571428571428; rank-qa: 0.10312204351939451\n",
        "fraction still correct = 0.9636471401758372\n",
        "1 evaluation results w/o re-ranking: 0.3867564308681672 / upper bound: 0.6498191318327974; rank-qa: 0.2770297427652733\n",
        "fraction still correct = 0.9492334757476752"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fahXvXmsRZSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}